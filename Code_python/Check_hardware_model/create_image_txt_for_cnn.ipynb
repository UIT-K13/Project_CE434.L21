{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd05c3f60802471494b60a2e66fd4ecd6fdf92055af140e68ee192931e29e235180",
   "display_name": "Python 3.8.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bitstring import Bits\n",
    "from bitstring import BitArray\n",
    "import pickle\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantization2d(data_arr, min_q, max_q, scale, offset):\n",
    "\trow, col = data_arr.shape\n",
    "\tdata_quantization = np.ones((row, col))\n",
    "\n",
    "\tfor i in range(row):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\tdata_quantization[i][j] = round((data_arr[i][j] / scale) + offset)\n",
    "\n",
    "\t\t\tif(data_quantization[i][j] > max_q):\n",
    "\t\t\t\tdata_quantization[i][j] = max_q\n",
    "\t\t\telif(data_quantization[i][j] < min_q):\n",
    "\t\t\t\tdata_quantization[i][j] = min_q\n",
    "\n",
    "\treturn data_quantization\n",
    "\n",
    "def Quantization3d(data, min_q, max_q, scale, offset):\n",
    "\trow, col, num_filter = data.shape\n",
    "\tdata_quantization = np.ones((row, col, num_filter))\n",
    "\n",
    "\tfor i in range(num_filter):\n",
    "\t\tdata_quantization[:, :, i] = Quantization2d(data[:, :, i], min_q, max_q, scale, offset)\n",
    "        \n",
    "\treturn data_quantization\n",
    "\n",
    "def Quantization4d(data, min_q, max_q, scale, offset):\n",
    "\trow, col, num_subfilter, num_filter = data.shape\n",
    "\tdata_quantization = np.ones((row, col, num_subfilter, num_filter))\n",
    "\n",
    "\tfor i in range(num_filter):\n",
    "\t\tdata_quantization[:, :, :, i] = Quantization3d(data[:, :, :, i], min_q, max_q, scale, offset)\n",
    "\n",
    "\treturn data_quantization\n",
    "\n",
    "def Dequantization2d(data_arr, scale, offset):\n",
    "\trow, col = data_arr.shape\n",
    "\tdata_dequantization = np.ones((row, col))\n",
    "\n",
    "\tfor i in range(row):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\tdata_dequantization[i][j] = (data_arr[i][j] - offset) * scale\n",
    "\n",
    "\treturn data_dequantization\n",
    "\n",
    "def\tRound_quantization2d(data_arr, min_q, max_q):\n",
    "\trow, col = data_arr.shape\n",
    "\tdata_round_quantization = np.ones((row, col))\n",
    "\n",
    "\tfor i in range(row):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\tdata = float(data_arr[i][j])\n",
    "\t\t\tdata_round_quantization[i][j] = round(data)\n",
    "\n",
    "\t\t\tif(data_round_quantization[i][j] > max_q):\n",
    "\t\t\t\tdata_round_quantization[i][j] = max_q\n",
    "\t\t\telif(data_round_quantization[i][j] < min_q):\n",
    "\t\t\t\tdata_round_quantization[i][j] = min_q\n",
    "\n",
    "\treturn data_round_quantization\n",
    "\n",
    "def\tRound_quantization3d(data, min_q, max_q):\n",
    "\trow, col, num_filter = data.shape\n",
    "\tdata_round_quantization = np.ones((row, col, num_filter))\n",
    "\n",
    "\tfor i in range(num_filter):\n",
    "\t\tdata_round_quantization[:, :, i] = Round_quantization2d(data[:, :, i], min_q, max_q)\n",
    "\n",
    "\treturn data_round_quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_int_to_binary(number, bit_width):\n",
    "    if((bit_width%4) != 0):\n",
    "        return str(Bits(int=number, length=bit_width))\n",
    "    else:\n",
    "        temp =  str(Bits(int=number, length=bit_width+1))\n",
    "        return '0b' + temp[-(len(temp)-3):]\n",
    "\n",
    "def convert_binary_to_hex(number, bit_width):\n",
    "\tif(bit_width <= 4):\n",
    "\t\treturn hex(int(number, 2))\n",
    "\telse:\n",
    "\t\tnumber = number[2:len(number)]\n",
    "\t\tdata_ret = ''\n",
    "\t\tindex = np.arange(bit_width, 1, -4)\n",
    "\t\tfor i in range(len(index)):\n",
    "\t\t\tif(index[i] >= 4):\n",
    "\t\t\t\ttemp = hex(int(number[index[i] - 4 : index[i]], 2))\n",
    "\t\t\t\tdata_ret = temp[-1:] + data_ret\n",
    "\t\t\telse:\n",
    "\t\t\t\ttemp = hex(int(number[0 : index[i]], 2))\n",
    "\t\t\t\tdata_ret = temp[-1:] + data_ret\n",
    "\t\t\n",
    "\t\treturn '0x' + data_ret\n",
    "\n",
    "def Load_Conv_and_W_and_Bias(data_path, load_option, conv_shape):\n",
    "\ttemp_data = np.loadtxt(data_path)\n",
    "\n",
    "\tif(load_option == 0): # ================== Conv\n",
    "\t\trow, col, num_sub_filter, num_filter = conv_shape # row = col\n",
    "\t\tdata = np.zeros((row, col, num_sub_filter, num_filter))\n",
    "\n",
    "\t\tindex = 0 # maximum index = num_sub_filter * num_filter\n",
    "\t\tfor m in range(num_filter):\n",
    "\t\t\tfor k in range(num_sub_filter):\n",
    "\t\t\t\tdata[:, :, k, m] = temp_data[index * row: index * row + 5, :]\n",
    "\t\t\t\tindex = index + 1\n",
    "\t\treturn data\n",
    "\telif(load_option == 1): # ================ W\n",
    "\t\treturn temp_data\n",
    "\telse: # ============================= Bias\n",
    "\t\treturn temp_data.reshape(-1, 1)\n",
    "\n",
    "def Load_data_matrix(data_path):\n",
    "\tdata = np.loadtxt(data_path)\n",
    "\treturn data\n",
    "\n",
    "def create_txt_file_for_input_verilog(input_data, bit_width, file_path):\n",
    "    verilog_file = open(file_path, mode = 'w')\n",
    "\n",
    "    input_data = input_data.reshape(-1, 1)\n",
    "\n",
    "    num_node, temp = input_data.shape\n",
    "\n",
    "    for i in range(num_node):\n",
    "        dec_data = int(input_data[i])\n",
    "        bin_data_temp = convert_int_to_binary(dec_data, bit_width)\n",
    "        bin_data = bin_data_temp[-bit_width:]\n",
    "        hex_data = convert_binary_to_hex('0b' + bin_data, bit_width)\n",
    "        if(i != (num_node - 1)):\n",
    "            verilog_file.write(str(hex_data[-(len(hex_data)-2):]) + '\\n')\n",
    "        else:\n",
    "            verilog_file.write(str(hex_data[-(len(hex_data)-2):]))\n",
    "    verilog_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_image = 1\n",
    "min_image = -1\n",
    "\n",
    "max_filter_conv0 = 0.64\n",
    "min_filter_conv0 = -0.64\n",
    "max_filter_conv1 = 0.94\n",
    "min_filter_conv1 = -0.94\n",
    "\n",
    "max_result_conv0 = 2.67\n",
    "min_result_conv0 = -2.67\n",
    "max_result_conv1 = 8.88\n",
    "min_result_conv1 = -8.88\n",
    "\n",
    "max_bias_conv0 = 0.35\n",
    "min_bias_conv0 = -0.35\n",
    "max_bias_conv1 = 0.16\n",
    "min_bias_conv1 = -0.16\n",
    "\n",
    "max_pooling0 = 1.75\n",
    "min_pooling0 = -1.75\n",
    "max_pooling1 = 2.84\n",
    "min_pooling1 = -2.84\n",
    "\n",
    "max_w0 = 1.02\n",
    "min_w0 = -1.02\n",
    "max_w1 = 0.78\n",
    "min_w1 = -0.78\n",
    "max_w2 = 0.85\n",
    "min_w2 = -0.85\n",
    "\n",
    "max_b0 = 0.21\n",
    "min_b0 = -0.21\n",
    "max_b1 = 0.19\n",
    "min_b1 = -0.19\n",
    "max_b2 = 0.24\n",
    "min_b2 = -0.24\n",
    "\n",
    "max_in = 2.84\n",
    "min_in = -2.84\n",
    "max_hd0 = 9.6\n",
    "min_hd0 = -9.6\n",
    "max_hd1 = 12.8\n",
    "min_hd1 = -12.8\n",
    "max_out_bf_act = 23.4\n",
    "min_out_bf_act = -23.4\n",
    "max_out = 1\n",
    "min_out = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================ Bit-width ============================================\n",
    "bit_width_image = 6\n",
    "bit_width_filter_conv0 = 6\n",
    "bit_width_filter_conv1 = 6\n",
    "bit_width_conv0 = 6\n",
    "bit_width_conv1 = 6\n",
    "bit_width_bias_conv0 = 6\n",
    "bit_width_bias_conv1 = 6\n",
    "bit_width_pooling0 = 6\n",
    "bit_width_pooling1 = 6\n",
    "bit_width_input = bit_width_pooling1\n",
    "\n",
    "bit_width_w0 = 6\n",
    "bit_width_w1 = 6\n",
    "bit_width_w2 = 6\n",
    "\n",
    "bit_width_b0 = 6\n",
    "bit_width_b1 = 6\n",
    "bit_width_b2 = 6\n",
    "\n",
    "bit_width_h0 = 6\n",
    "bit_width_h1 = 6\n",
    "bit_width_bf_sigmoid = 6\n",
    "bit_width_output = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================ Max-min quantization value ============================================\n",
    "max_image_q = 2**(bit_width_image-1)-1\n",
    "min_image_q = -2**(bit_width_image-1)\n",
    "max_filter_conv0_q = 2**(bit_width_filter_conv0-1)-1\n",
    "min_filter_conv0_q = -2**(bit_width_filter_conv0-1)\n",
    "max_filter_conv1_q = 2**(bit_width_filter_conv1-1)-1\n",
    "min_filter_conv1_q = -2**(bit_width_filter_conv1-1)\n",
    "max_conv0_q = 2**(bit_width_conv0-1)-1\n",
    "min_conv0_q = -2**(bit_width_conv0-1)\n",
    "max_conv1_q = 2**(bit_width_conv1-1)-1\n",
    "min_conv1_q = -2**(bit_width_conv1-1)\n",
    "max_bias_conv0_q = 2**(bit_width_bias_conv0-1)-1\n",
    "min_bias_conv0_q = -2**(bit_width_bias_conv0-1)\n",
    "max_bias_conv1_q = 2**(bit_width_bias_conv1-1)-1\n",
    "min_bias_conv1_q = -2**(bit_width_bias_conv1-1)\n",
    "max_pooling0_q = 2**(bit_width_pooling0-1)-1\n",
    "min_pooling0_q = -2**(bit_width_pooling0-1)\n",
    "max_pooling1_q = 2**(bit_width_pooling1-1)-1\n",
    "min_pooling1_q = -2**(bit_width_pooling1-1)\n",
    "\n",
    "max_w0_q = 2**(bit_width_w0-1)-1\n",
    "min_w0_q = -2**(bit_width_w0-1)\n",
    "max_w1_q = 2**(bit_width_w1-1)-1\n",
    "min_w1_q = -2**(bit_width_w1-1)\n",
    "max_w2_q = 2**(bit_width_w2-1)-1\n",
    "min_w2_q = -2**(bit_width_w2-1)\n",
    "\n",
    "max_b0_q = 2**(bit_width_b0-1)-1\n",
    "min_b0_q = -2**(bit_width_b0-1)\n",
    "max_b1_q = 2**(bit_width_b1-1)-1\n",
    "min_b1_q = -2**(bit_width_b1-1)\n",
    "max_b2_q = 2**(bit_width_b2-1)-1\n",
    "min_b2_q = -2**(bit_width_b2-1)\n",
    "\n",
    "max_input_q = 2**(bit_width_input-1)-1\n",
    "min_input_q = -2**(bit_width_input-1)\n",
    "max_hd0_q = 2**(bit_width_h0-1)-1\n",
    "min_hd0_q = -2**(bit_width_h0-1)\n",
    "max_hd1_q = 2**(bit_width_h1-1)-1\n",
    "min_hd1_q = -2**(bit_width_h1-1)\n",
    "max_bf_sigmoid_q = 2**(bit_width_bf_sigmoid-1)-1\n",
    "min_bf_sigmoid_q = -2**(bit_width_bf_sigmoid-1)\n",
    "max_output_q = 2**(bit_width_output-1)-1\n",
    "min_output_q = -2**(bit_width_output-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================ Scale and offset for w1 & bias ============================================\n",
    "# Quantied number = (X/Scale) + Offset\n",
    "scale_image = (max_image - min_image)/(max_image_q - min_image_q)\n",
    "scale_filter_conv0 = (max_filter_conv0 - min_filter_conv0)/(max_filter_conv0_q - min_filter_conv0_q)\n",
    "scale_filter_conv1 = (max_filter_conv1 - min_filter_conv1)/(max_filter_conv1_q - min_filter_conv1_q)\n",
    "scale_conv0 = (max_result_conv0 - min_result_conv0)/(max_conv0_q - min_conv0_q)\n",
    "scale_conv1 = (max_result_conv1 - min_result_conv1)/(max_conv1_q - min_conv1_q)\n",
    "scale_bias_conv0 = (max_bias_conv0 - min_bias_conv0)/(max_bias_conv0_q - min_bias_conv0_q)\n",
    "scale_bias_conv1 = (max_bias_conv1 - min_bias_conv1)/(max_bias_conv1_q - min_bias_conv1_q)\n",
    "scale_pooling0 = (max_pooling0 - min_pooling0)/(max_pooling0_q - min_pooling0_q)\n",
    "scale_pooling1 = (max_pooling1 - min_pooling1)/(max_pooling1_q - min_pooling1_q)\n",
    "\n",
    "scale_w0 = (max_w0 - min_w0)/(max_w0_q - min_w0_q)\n",
    "scale_w1 = (max_w1 - min_w1)/(max_w1_q - min_w1_q)\n",
    "scale_w2 = (max_w2 - min_w2)/(max_w2_q - min_w2_q)\n",
    "\n",
    "scale_b0 = (max_b0 - min_b0)/(max_b0_q - min_b0_q)\n",
    "scale_b1 = (max_b1 - min_b1)/(max_b1_q - min_b1_q)\n",
    "scale_b2 = (max_b2 - min_b2)/(max_b2_q - min_b2_q)\n",
    "\n",
    "scale_input = (max_in - min_in)/(max_input_q - min_input_q)\n",
    "scale_hd0 = (max_hd0 - min_hd0)/(max_hd0_q - min_hd0_q)\n",
    "scale_hd1 = (max_hd1 - min_hd1)/(max_hd1_q - min_hd1_q)\n",
    "scale_bf_sigmoid = (max_out_bf_act - min_out_bf_act)/(max_bf_sigmoid_q - min_bf_sigmoid_q)\n",
    "scale_output = (max_out - min_out)/(max_output_q - min_output_q)\n",
    "\n",
    "offset_image = round((max_image*min_image_q - min_image*max_image_q)/(max_image - min_image))\n",
    "offset_filter_conv0 = round((max_filter_conv0*min_filter_conv0_q - min_filter_conv0*max_filter_conv0_q)/(max_filter_conv0 - min_filter_conv0))\n",
    "offset_filter_conv1 = round((max_filter_conv1*min_filter_conv1_q - min_filter_conv1*max_filter_conv1_q)/(max_filter_conv1 - min_filter_conv1))\n",
    "offset_conv0 = round((max_result_conv0*min_conv0_q - min_result_conv0*max_conv0_q)/(max_result_conv0 - min_result_conv0))\n",
    "offset_conv1 = round((max_result_conv1*min_conv1_q - min_result_conv1*max_conv1_q)/(max_result_conv1 - min_result_conv1))\n",
    "offset_bias_conv0 = round((max_bias_conv0*min_bias_conv0_q - min_bias_conv0*max_bias_conv0_q)/(max_bias_conv0 - min_bias_conv0))\n",
    "offset_bias_conv1 = round((max_bias_conv1*min_bias_conv1_q - min_bias_conv1*max_bias_conv1_q)/(max_bias_conv1 - min_bias_conv1))\n",
    "offset_pooling0 = round((max_pooling0*min_pooling0_q - min_pooling0*max_pooling0_q)/(max_pooling0 - min_pooling0))\n",
    "offset_pooling1 = round((max_pooling1*min_pooling1_q - min_pooling1*max_pooling1_q)/(max_pooling1 - min_pooling1))\n",
    "\n",
    "offset_w0 = round((max_w0*min_w0_q - min_w0*max_w0_q)/(max_w0 - min_w0))\n",
    "offset_w1 = round((max_w1*min_w1_q - min_w1*max_w1_q)/(max_w1 - min_w1))\n",
    "offset_w2 = round((max_w2*min_w2_q - min_w2*max_w2_q)/(max_w2 - min_w2))\n",
    "\n",
    "offset_b0 = round((max_b0*min_b0_q - min_b0*max_b0_q)/(max_b0 - min_b0))\n",
    "offset_b1 = round((max_b1*min_b1_q - min_b1*max_b1_q)/(max_b1 - min_b1))\n",
    "offset_b2 = round((max_b2*min_b2_q - min_b2*max_b2_q)/(max_b2 - min_b2))\n",
    "\n",
    "offset_input = round((max_in*min_input_q - min_in*max_input_q)/(max_in - min_in))\n",
    "offset_hd0 = round((max_hd0*min_hd0_q - min_hd0*max_hd0_q)/(max_hd0 - min_hd0))\n",
    "offset_hd1 = round((max_hd1*min_hd1_q - min_hd1*max_hd1_q)/(max_hd1 - min_hd1))\n",
    "offset_bf_sigmoid = round((max_out_bf_act*min_bf_sigmoid_q - min_out_bf_act*max_bf_sigmoid_q)/(max_out_bf_act - min_out_bf_act))\n",
    "offset_output = round((max_out*min_output_q - min_out*max_output_q)/(max_out - min_out))\n",
    "\n",
    "# ============================================ Scale for quantize ============================================\n",
    "# X * Scale \n",
    "scale_calculate_convolution_0 = (scale_image*scale_filter_conv0)/scale_conv0\n",
    "scale_for_pooling0 = scale_conv0/scale_pooling0\n",
    "scale_calculate_convolution_1 = (scale_pooling0*scale_filter_conv1)/scale_conv1\n",
    "scale_for_pooling1 = scale_conv1/scale_pooling1\n",
    "\n",
    "scale_for_W0_x_Flatten = (scale_input*scale_w0)/scale_hd0\n",
    "scale_for_W1_x_hd0 = (scale_hd0*scale_w1)/scale_hd1\n",
    "scale_for_W2_x_hd1 = (scale_hd1*scale_w2)/scale_bf_sigmoid\n",
    "\n",
    "scale_for_B0_conv = scale_bias_conv0/scale_conv0\n",
    "scale_for_B1_conv = scale_bias_conv1/scale_conv1\n",
    "\n",
    "scale_for_B0_fc = scale_b0/scale_hd0\n",
    "scale_for_B1_fc = scale_b1/scale_hd1\n",
    "scale_for_B2_fc = scale_b2/scale_bf_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv0_shape = (5, 5, 1, 6)\n",
    "Conv1_shape = (5, 5, 6, 16)\n",
    "\n",
    "image_path_verilog = '../../Weight_and_bias_of_model_verilog/image.txt'\n",
    "Conv0_path_verilog = '../../Weight_and_bias_of_model_python/Conv0.txt'\n",
    "Bias_conv0_path_verilog = '../../Weight_and_bias_of_model_python/Bias_conv0.txt'\n",
    "Conv1_path_verilog = '../../Weight_and_bias_of_model_python/Conv1.txt'\n",
    "Bias_conv1_path_verilog = '../../Weight_and_bias_of_model_python/Bias_conv1.txt'\n",
    "\n",
    "Conv0_path = '../../Weight_and_bias_of_model_python/Conv0.txt'\n",
    "Bias_conv0_path = '../../Weight_and_bias_of_model_python/Bias_conv0.txt'\n",
    "Conv1_path = '../../Weight_and_bias_of_model_python/Conv1.txt'\n",
    "Bias_conv1_path = '../../Weight_and_bias_of_model_python/Bias_conv1.txt'\n",
    "\n",
    "W0_path = '../../Weight_and_bias_of_model_python/W0.txt'\n",
    "W1_path = '../../Weight_and_bias_of_model_python/W1.txt'\n",
    "W2_path = '../../Weight_and_bias_of_model_python/W2.txt'\n",
    "\n",
    "B0_path = '../../Weight_and_bias_of_model_python/B0.txt'\n",
    "B1_path = '../../Weight_and_bias_of_model_python/B1.txt'\n",
    "B2_path = '../../Weight_and_bias_of_model_python/B2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"../../Dataset/Data_test_10000.pickle\",\"rb\")\n",
    "image_test = pickle.load(pickle_in)\n",
    "pickle_in = open(\"../../Dataset/Label_test_10000.pickle\",\"rb\")\n",
    "label_test = pickle.load(pickle_in)\n",
    "\n",
    "Conv0 = Load_Conv_and_W_and_Bias(Conv0_path, 1, 0)\n",
    "Bias_conv0 = Load_Conv_and_W_and_Bias(Bias_conv0_path, 2, 0)\n",
    "Conv1 = Load_Conv_and_W_and_Bias(Conv1_path, 1, 0)\n",
    "Bias_conv1 = Load_Conv_and_W_and_Bias(Bias_conv1_path, 2, 0)\n",
    "\n",
    "Conv1_temp = Load_Conv_and_W_and_Bias(Conv1_path, 0, Conv1_shape)\n",
    "\n",
    "W0 = Load_Conv_and_W_and_Bias(W0_path, 1, 0)\n",
    "W1 = Load_Conv_and_W_and_Bias(W1_path, 1, 0)\n",
    "W2 = Load_Conv_and_W_and_Bias(W2_path, 1, 0)\n",
    "\n",
    "B0 = Load_Conv_and_W_and_Bias(B0_path, 2, 0)\n",
    "B1 = Load_Conv_and_W_and_Bias(B1_path, 2, 0)\n",
    "B2 = Load_Conv_and_W_and_Bias(B2_path, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(30, 5)\n(6, 1)\n(480, 5)\n(16, 1)\n(5, 5, 6, 16)\n"
     ]
    }
   ],
   "source": [
    "print(Conv0.shape)\n",
    "print(Bias_conv0.shape)\n",
    "print(Conv1.shape)\n",
    "print(Bias_conv1.shape)\n",
    "print(Conv1_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.04851859 -0.1438246  -0.54313666 -0.36861646  0.03476332]\n [ 0.17254019 -0.06478588 -0.08988825  0.10441433  0.19314076]\n [ 0.24737994 -0.06551661 -0.23020874 -0.0156035  -0.00678222]\n [-0.04441087 -0.09678386 -0.14068176  0.07402343 -0.11665808]\n [ 0.08713108  0.00606869  0.03400352  0.14854686 -0.18251422]]\n\n==============\n\n[[ 0.0213694   0.09157427  0.19397451  0.06696144  0.08213645]\n [-0.08692447 -0.22725967 -0.22914405 -0.11691716 -0.30679813]\n [ 0.01664766  0.08855011 -0.20456885 -0.02261611 -0.1619465 ]\n [ 0.34814632  0.01951889  0.13625239  0.02631405 -0.2701475 ]\n [ 0.05840284 -0.10904247 -0.2699256  -0.6881372  -0.14021902]]\n\n==============\n\n[[ 0.04851859]\n [-0.1438246 ]\n [-0.54313666]\n ...\n [-0.03556796]\n [-0.43978828]\n [-0.68106097]]\n"
     ]
    }
   ],
   "source": [
    "print(Conv1_temp[:, :, 0, 0])\n",
    "print('\\n==============\\n')\n",
    "print(Conv1_temp[:, :, 1, 0])\n",
    "print('\\n==============\\n')\n",
    "print(Conv1.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv0 = Quantization2d(Conv0, min_filter_conv0_q, max_filter_conv0_q, scale_filter_conv0, 0)\n",
    "Bias_conv0 = Quantization2d(Bias_conv0, min_bias_conv0_q, max_bias_conv0_q, scale_bias_conv0, 0)\n",
    "Conv1 = Quantization2d(Conv1, min_filter_conv1_q, max_filter_conv1_q, scale_filter_conv1, 0)\n",
    "Bias_conv1 = Quantization2d(Bias_conv1, min_bias_conv1_q, max_bias_conv1_q, scale_bias_conv1, 0)\n",
    "\n",
    "W0 = Quantization2d(W0, min_w0_q, max_w0_q, scale_w0, 0)\n",
    "W1 = Quantization2d(W1, min_w1_q, max_w1_q, scale_w1, 0)\n",
    "W2 = Quantization2d(W2, min_w2_q, max_w2_q, scale_w2, 0)\n",
    "\n",
    "B0 = Quantization2d(B0, min_b0_q, max_b0_q, scale_b0, 0)\n",
    "B1 = Quantization2d(B1, min_b1_q, max_b1_q, scale_b1, 0)\n",
    "B2 = Quantization2d(B2, min_b2_q, max_b2_q, scale_b2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "quatized_image_temp = Quantization3d(image_test[1], min_input_q, max_input_q, scale_input, 0)\n",
    "\n",
    "quatized_image = quatized_image_temp[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(quatized_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_txt_file_for_input_verilog(quatized_image, bit_width_image, image_path_verilog)\n",
    "\n",
    "create_txt_file_for_input_verilog(quatized_image, bit_width_filter_conv0, Conv0_path_verilog)\n",
    "create_txt_file_for_input_verilog(quatized_image, bit_width_bias_conv0, Bias_conv0_path_verilog)\n",
    "create_txt_file_for_input_verilog(quatized_image, bit_width_filter_conv1, Conv1_path_verilog)\n",
    "create_txt_file_for_input_verilog(quatized_image, bit_width_bias_conv1, Bias_conv1_path_verilog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[[4 2]\n   [3 4]\n   [4 1]]\n\n  [[2 0]\n   [0 0]\n   [0 0]]]\n\n\n [[[4 1]\n   [3 2]\n   [4 3]]\n\n  [[2 0]\n   [1 1]\n   [0 0]]]]\n========\n[[[4 1]\n  [3 2]\n  [4 3]]\n\n [[2 0]\n  [1 1]\n  [0 0]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(0, 5, (2, 2, 3, 2))\n",
    "print(a)\n",
    "print('========')\n",
    "print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[3]\n [2]\n [0]\n [1]\n [4]\n [4]\n [4]\n [3]\n [2]\n [0]\n [4]\n [3]\n [1]\n [3]\n [3]\n [4]\n [2]\n [1]\n [0]\n [2]\n [2]\n [0]\n [3]\n [2]]\n"
     ]
    }
   ],
   "source": [
    "b = a.reshape(-1, 1)\n",
    "print(b)"
   ]
  }
 ]
}