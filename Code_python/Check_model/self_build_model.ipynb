{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd05c3f60802471494b60a2e66fd4ecd6fdf92055af140e68ee192931e29e235180",
   "display_name": "Python 3.8.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(data):\n",
    "\tif(data >= 0):\n",
    "\t\treturn data\n",
    "\telse: \n",
    "\t\treturn 0\n",
    "def ReLU_2d(data):\n",
    "\trow, col = data.shape\n",
    "\tdata_ret = np.zeros((row, col))\n",
    "\n",
    "\tfor i in range(row):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\tdata_ret[i, j] = ReLU(data[i, j])\n",
    "\t\n",
    "\treturn data_ret\n",
    "\n",
    "def ReLU_3d(data):\n",
    "\trow, col, num_filter = data.shape\n",
    "\tdata_ret = np.zeros((row, col, num_filter))\n",
    "\n",
    "\tfor i in range(num_filter):\n",
    "\t\tdata_ret[:, :, i] = ReLU_2d(data[:, :, i])\n",
    "\n",
    "\treturn data_ret\n",
    "\n",
    "def Sigmoid(data):\n",
    "\treturn 1 / (1 + math.exp(-data))\n",
    "\n",
    "def Sigmoid_2d(data):\n",
    "\trow, col = data.shape\n",
    "\tdata_ret = np.zeros((row, col))\n",
    "\n",
    "\tfor i in range(row):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\tdata_ret[i, j] = Sigmoid(data[i, j])\n",
    "\t\n",
    "\treturn data_ret\n",
    "\n",
    "def max_pooling(matrix):\n",
    "\trow, col = matrix.shape\n",
    "\n",
    "\tmax_value = 0\n",
    "\n",
    "\tfor i in range(row):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\tif(matrix[i][j] > max_value):\n",
    "\t\t\t\tmax_value = matrix[i][j]\n",
    "\treturn max_value\n",
    "\n",
    "def avg_pooling(matrix):\n",
    "\trow, col = matrix.shape\n",
    "\n",
    "\tsum_value = 0\n",
    "\n",
    "\tfor i in range(row):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\t\tsum_value = sum_value + matrix[i][j]\n",
    "\n",
    "\tavg_value = sum_value/(col*row)\n",
    "\treturn avg_value\n",
    "\n",
    "def median_pooling(matrix):\n",
    "\trow, col = matrix.shape\n",
    "\n",
    "\tmatrix = np.reshape(matrix, (1, row*col))\n",
    "\n",
    "\tmatrix = np.sort(matrix)\n",
    "\n",
    "\tnum_element = row*col\n",
    "\n",
    "\tmedian_index = int(num_element/2)\n",
    "\n",
    "\treturn matrix[0, median_index]\n",
    "\n",
    "def pooling_2d(x_matrix, dim_filter, stride, padding, pooling_option):\n",
    "\tx_row, x_col = x_matrix.shape\n",
    "\tfilter_row, filter_col = dim_filter\n",
    "\n",
    "\ty_row = int(((x_row - filter_row + 2*padding)/stride) + 1)\n",
    "\ty_col = int(((x_col - filter_col + 2*padding)/stride) + 1)\n",
    "\n",
    "\tif(padding >= 1):\n",
    "\t\ttemp_matrix = x_matrix\n",
    "\t\tx_row = x_row + 2*padding\n",
    "\t\tx_col = x_col + 2*padding\n",
    "\t\tx_matrix = np.zeros((x_row, x_col))\n",
    "\t\tx_matrix[0+padding:x_row-padding, 0+padding:x_col-padding] = temp_matrix\n",
    "\n",
    "\ty = np.zeros((y_row, y_col))\n",
    "\n",
    "\tindex_row = np.arange(start=0, stop=x_row-filter_row+1, step=stride)\n",
    "\tindex_col = np.arange(start=0, stop=x_col-filter_col+1, step=stride)\n",
    "\tfor i in range(len(index_row)):\n",
    "\t\tfor j in range(len(index_col)):\n",
    "\t\t\tsub_matrix = x_matrix[index_row[i]:index_row[i]+filter_row, index_col[j]:index_col[j]+filter_col]\n",
    "\n",
    "\t\t\tif(pooling_option == 0):\n",
    "\t\t\t\ty[i, j] = max_pooling(sub_matrix)\n",
    "\t\t\telif(pooling_option == 1):\n",
    "\t\t\t\ty[i, j] = avg_pooling(sub_matrix)\n",
    "\t\t\telse:\n",
    "\t\t\t\ty[i, j] = median_pooling(sub_matrix)\n",
    "\t\t\t\n",
    "\treturn y\n",
    "\n",
    "def pooling_3d(x_matrix, dim_filter, stride, padding, pooling_option):\n",
    "\tx_row, x_col, num_filter = x_matrix.shape\n",
    "\tfilter_row, filter_col = dim_filter\n",
    "\n",
    "\ty_row = int(((x_row - filter_row + 2*padding)/stride) + 1)\n",
    "\ty_col = int(((x_col - filter_col + 2*padding)/stride) + 1)\n",
    "\n",
    "\ty = np.zeros((y_row, y_col, num_filter))\n",
    "\n",
    "\tfor i in range(num_filter):\n",
    "\t\tif(pooling_option == 0):\n",
    "\t\t\ty[:, :, i] = pooling_2d(x_matrix[:, :, i], dim_filter, stride, padding, pooling_option)\n",
    "\t\telif(pooling_option == 1):\n",
    "\t\t\ty[:, :, i] = pooling_2d(x_matrix[:, :, i], dim_filter, stride, padding, pooling_option)\n",
    "\t\telse:\n",
    "\t\t\ty[:, :, i] = pooling_2d(x_matrix[:, :, i], dim_filter, stride, padding, pooling_option)\n",
    "\n",
    "\treturn y\n",
    "\n",
    "def conv(x_matrix, filter_matrix):\n",
    "\trow, col = x_matrix.shape\n",
    "\ty = np.zeros((row, col))\n",
    "\n",
    "\tfor i in range(row):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\ty[i, j] = x_matrix[i, j]*filter_matrix[i, j]\n",
    "\t\n",
    "\treturn y.sum()\n",
    "\t\n",
    "def conv2(x_matrix, filter_matrix, stride, padding):\n",
    "\tx_row, x_col = x_matrix.shape\n",
    "\tfilter_row, filter_col = filter_matrix.shape \n",
    "\n",
    "\ty_row = int(((x_row - filter_row + 2*padding)/stride) + 1)\n",
    "\ty_col = int(((x_col - filter_col + 2*padding)/stride) + 1)\n",
    "\n",
    "\tif(padding >= 1):\n",
    "\t\ttemp_matrix = x_matrix\n",
    "\t\tx_row = x_row + 2*padding\n",
    "\t\tx_col = x_col + 2*padding\n",
    "\t\tx_matrix = np.zeros((x_row, x_col))\n",
    "\t\tx_matrix[0+padding:x_row-padding, 0+padding:x_col-padding] = temp_matrix\n",
    "\n",
    "\ty = np.zeros((y_row, y_col))\n",
    "\n",
    "\tindex_row = np.arange(start=0, stop=x_row-filter_row+1, step=stride)\n",
    "\tindex_col = np.arange(start=0, stop=x_col-filter_col+1, step=stride)\n",
    "\tfor i in range(len(index_row)):\n",
    "\t\tfor j in range(len(index_col)):\n",
    "\t\t\tsub_matrix = x_matrix[index_row[i]:index_row[i]+filter_row, index_col[j]:index_col[j]+filter_col]\n",
    "\t\t\ty[i, j] = conv(sub_matrix, filter_matrix)\n",
    "\treturn y\n",
    "\n",
    "def conv3(x_matrix, filter_matrix, stride, padding):\n",
    "\trow_filter, col_filter, num_sub_filter, num_filter = filter_matrix.shape \t\t\t\t# row_filter_matrix = col_filter_matrix\n",
    "\trow_x, col_x, num_x = x_matrix.shape \t\t\t\t\t\t\t\t\t\t\t\t\t# row_x = col_x\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# num_sub_filter = num_x\n",
    "\ty_row = int(((row_x - row_filter + 2*padding)/stride) + 1)\n",
    "\ty_col = int(((col_x - col_filter + 2*padding)/stride) + 1)\n",
    "\t\n",
    "\tdata = np.zeros((y_row, y_col, num_filter))\n",
    "\tfor i in range(num_filter):\n",
    "\t\tdata_temp = np.zeros((y_row, y_col))\n",
    "\n",
    "\t\tfor j in range(num_sub_filter):\n",
    "\t\t\tdata_temp = data_temp + conv2(x_matrix[:, :, j], filter_matrix[:, :, j, i], stride, padding)\n",
    "\t\t\n",
    "\t\tdata[:, :, i] = data_temp\n",
    "\n",
    "\treturn data\n",
    "\n",
    "def add_bias_after_conv(conv_result, bias):\n",
    "\trow, col, num_filter = conv_result.shape\n",
    "\n",
    "\tfor i in range(num_filter):\n",
    "\t\tconv_result[:, :, i] = conv_result[:, :, i] + bias[i, :]\n",
    "\n",
    "\treturn conv_result\n",
    "\n",
    "def Feed_forward_Lenet_5(image, conv0_filter, bias_conv0, conv1_filter, bias_conv1, W0, W1, W2, B0, B1, B2, max_result_conv0, min_result_conv0, max_result_conv1, min_result_conv1, max_pooling0, min_pooling0, max_pooling1, min_pooling1, max_hd0, min_hd0, max_hd1, min_hd1, max_out_bf_act, min_out_gf_act):\n",
    "\tstride = 1\n",
    "\tpadding = 0\n",
    "\tstride_pooling = 2\n",
    "\tpadding_pooling = 0\n",
    "\tpooling_option = 1\n",
    "\n",
    "\t# Convolution layer 0\n",
    "\tconv0_result = conv3(image, conv0_filter, stride, padding)\n",
    "\tadd_bias_after_conv0_bf_relu = add_bias_after_conv(conv0_result, bias_conv0)\n",
    "\tadd_bias_after_conv0 = ReLU_3d(add_bias_after_conv0_bf_relu)\n",
    "\tpooling0 = pooling_3d(add_bias_after_conv0, (2, 2), stride_pooling, padding_pooling, pooling_option)\n",
    "\t\n",
    "\n",
    "\t# Convolution layer 1\n",
    "\tconv1_result = conv3(pooling0, conv1_filter, stride, padding)\n",
    "\tadd_bias_after_conv1_bf_relu = add_bias_after_conv(conv1_result, bias_conv1)\n",
    "\tadd_bias_after_conv1 = ReLU_3d(add_bias_after_conv1_bf_relu)\n",
    "\tpooling1 = pooling_3d(add_bias_after_conv1, (2, 2), stride_pooling, padding_pooling, pooling_option)\n",
    "\t\n",
    "\t# Fully connected\n",
    "\tflatten = pooling1.reshape(-1, 1)\n",
    "\thd_layer0_bf_relu = np.dot(W0, flatten) + B0\n",
    "\thd_layer0 = ReLU_2d(hd_layer0_bf_relu)\n",
    "\thd_layer1_bf_relu = np.dot(W1, hd_layer0) + B1\n",
    "\thd_layer1 = ReLU_2d(hd_layer1_bf_relu)\n",
    "\toutput_bf_sigmoid = np.dot(W2, hd_layer1) + B2\n",
    "\toutput = Sigmoid_2d(output_bf_sigmoid)\n",
    "\t\n",
    "\tmax_data = 0\n",
    "\tresult = 0\n",
    "\tfor i in range(output.shape[0]):\n",
    "\t\tif(output[i, :] > max_data):\n",
    "\t\t\tmax_data = output[i, :]\n",
    "\t\t\tresult = i\n",
    "\t\n",
    "\tif(max_result_conv0 < np.amax(add_bias_after_conv0_bf_relu)):\n",
    "\t\tmax_result_conv0 = np.amax(add_bias_after_conv0_bf_relu)\n",
    "\tif(min_result_conv0 > np.amin(add_bias_after_conv0_bf_relu)):\n",
    "\t\tmin_result_conv0 = np.amin(add_bias_after_conv0_bf_relu)\n",
    "\t\n",
    "\tif(max_result_conv1 < np.amax(add_bias_after_conv1_bf_relu)):\n",
    "\t\tmax_result_conv1 = np.amax(add_bias_after_conv1_bf_relu)\n",
    "\tif(min_result_conv1 > np.amin(add_bias_after_conv1_bf_relu)):\n",
    "\t\tmin_result_conv1 = np.amin(add_bias_after_conv1_bf_relu)\n",
    "\t\n",
    "\tif(max_pooling0 < np.amax(pooling0)):\n",
    "\t\tmax_pooling0 = np.amax(pooling0)\n",
    "\tif(min_pooling0 > np.amin(pooling0)):\n",
    "\t\tmin_pooling0 = np.amin(pooling0)\n",
    "\n",
    "\tif(max_pooling1 < np.amax(pooling1)):\n",
    "\t\tmax_pooling1 = np.amax(pooling1)\n",
    "\tif(max_pooling1 > np.amin(pooling1)):\n",
    "\t\tmin_pooling1 = np.amin(pooling1)\n",
    "\t\n",
    "\tif(max_hd0 < np.amax(hd_layer0_bf_relu)):\n",
    "\t\tmax_hd0 = np.amax(hd_layer0_bf_relu)\n",
    "\tif(min_hd0 > np.amin(hd_layer0_bf_relu)):\n",
    "\t\tmin_hd0 = np.amin(hd_layer0_bf_relu)\n",
    "\t\n",
    "\tif(max_hd1 < np.amax(hd_layer1_bf_relu)):\n",
    "\t\tmax_hd1 = np.amax(hd_layer1_bf_relu)\n",
    "\tif(min_hd1 > np.amin(hd_layer1_bf_relu)):\n",
    "\t\tmin_hd1 = np.amin(hd_layer1_bf_relu)\n",
    "\t\n",
    "\tif(max_out_bf_act < np.amax(output_bf_sigmoid)):\n",
    "\t\tmax_out_bf_act = np.amax(output_bf_sigmoid)\n",
    "\tif(min_out_gf_act > np.amin(output_bf_sigmoid)):\n",
    "\t\tmin_out_gf_act = np.amin(output_bf_sigmoid)\n",
    "\n",
    "\treturn result, max_result_conv0, min_result_conv0, max_result_conv1, min_result_conv1, max_pooling0, min_pooling0, max_pooling1, min_pooling1, max_hd0, min_hd0, max_hd1, min_hd1, max_out_bf_act, min_out_gf_act\n",
    "\n",
    "def Load_Conv_and_W_and_Bias(data_path, load_option, conv_shape):\n",
    "\ttemp_data = np.loadtxt(data_path)\n",
    "\n",
    "\tif(load_option == 0): # ================== Conv\n",
    "\t\trow, col, num_sub_filter, num_filter = conv_shape # row = col\n",
    "\t\tdata = np.zeros((row, col, num_sub_filter, num_filter))\n",
    "\n",
    "\t\tindex = 0 # maximum index = num_sub_filter * num_filter\n",
    "\t\tfor m in range(num_filter):\n",
    "\t\t\tfor k in range(num_sub_filter):\n",
    "\t\t\t\tdata[:, :, k, m] = temp_data[index * row: index * row + 5, :]\n",
    "\t\t\t\tindex = index + 1\n",
    "\t\treturn data\n",
    "\telif(load_option == 1): # ================ W\n",
    "\t\treturn temp_data\n",
    "\telse: # ============================= Bias\n",
    "\t\treturn temp_data.reshape(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv0_shape = (5, 5, 1, 6)\n",
    "Conv1_shape = (5, 5, 6, 16)\n",
    "\n",
    "Conv0_path = '../../Weight_and_bias_of_model_python/Conv0.txt'\n",
    "Bias_conv0_path = '../../Weight_and_bias_of_model_python/Bias_conv0.txt'\n",
    "Conv1_path = '../../Weight_and_bias_of_model_python/Conv1.txt'\n",
    "Bias_conv1_path = '../../Weight_and_bias_of_model_python/Bias_conv1.txt'\n",
    "\n",
    "W0_path = '../../Weight_and_bias_of_model_python/W0.txt'\n",
    "W1_path = '../../Weight_and_bias_of_model_python/W1.txt'\n",
    "W2_path = '../../Weight_and_bias_of_model_python/W2.txt'\n",
    "\n",
    "B0_path = '../../Weight_and_bias_of_model_python/B0.txt'\n",
    "B1_path = '../../Weight_and_bias_of_model_python/B1.txt'\n",
    "B2_path = '../../Weight_and_bias_of_model_python/B2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"../../Dataset/Data_test_10000.pickle\",\"rb\")\n",
    "image_test = pickle.load(pickle_in)\n",
    "pickle_in = open(\"../../Dataset/Label_test_10000.pickle\",\"rb\")\n",
    "label_test = pickle.load(pickle_in)\n",
    "\n",
    "Conv0 = Load_Conv_and_W_and_Bias(Conv0_path, 0, Conv0_shape)\n",
    "Bias_conv0 = Load_Conv_and_W_and_Bias(Bias_conv0_path, 2, 0)\n",
    "Conv1 = Load_Conv_and_W_and_Bias(Conv1_path, 0, Conv1_shape)\n",
    "Bias_conv1 = Load_Conv_and_W_and_Bias(Bias_conv1_path, 2, 0)\n",
    "\n",
    "W0 = Load_Conv_and_W_and_Bias(W0_path, 1, 0)\n",
    "W1 = Load_Conv_and_W_and_Bias(W1_path, 1, 0)\n",
    "W2 = Load_Conv_and_W_and_Bias(W2_path, 1, 0)\n",
    "\n",
    "B0 = Load_Conv_and_W_and_Bias(B0_path, 2, 0)\n",
    "B1 = Load_Conv_and_W_and_Bias(B1_path, 2, 0)\n",
    "B2 = Load_Conv_and_W_and_Bias(B2_path, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n============================== Weight in convolution layer ==============================\n\nMax weight in conv layer 0:  0.45626965 \nMin weight in conv layer 0:  -0.6334114\nMax weight in conv layer 1:  0.5986896 \nMin weight in conv layer 1:  -0.9331202\n\n============================== Bias in convolution layer ==============================\n\nMax bias in conv layer 0:  0.03692436 \nMin bias in conv layer 0:  -0.34630153\nMax bias in conv layer 1:  0.020025745 \nMin bias in conv layer 1:  -0.15468165\n\n============================== Weight in FC ==============================\n\nMax w in W0:  0.8224239 \nMin w in W0:  -1.0181603\nMax w in W1:  0.777616 \nMin w in W1:  -0.7706447\nMax w in W2:  0.46389437 \nMin w in W2:  -0.84771866\n\n=================================== Bias in FC ===================================\n\nMax bias in B0:  0.1809927 \nMin bias in B0:  -0.20980695\nMax bias in B1:  0.18734296 \nMin bias in B1:  -0.18926921\nMax bias in B2:  0.23310512 \nMin bias in B2:  -0.1263325\n"
     ]
    }
   ],
   "source": [
    "print('\\n============================== Weight in convolution layer ==============================\\n')\n",
    "print('Max weight in conv layer 0: ', np.amax(Conv0), '\\nMin weight in conv layer 0: ', np.amin(Conv0))\n",
    "print('Max weight in conv layer 1: ', np.amax(Conv1), '\\nMin weight in conv layer 1: ', np.amin(Conv1))\n",
    "print('\\n============================== Bias in convolution layer ==============================\\n')\n",
    "print('Max bias in conv layer 0: ', np.amax(Bias_conv0), '\\nMin bias in conv layer 0: ', np.amin(Bias_conv0))\n",
    "print('Max bias in conv layer 1: ', np.amax(Bias_conv1), '\\nMin bias in conv layer 1: ', np.amin(Bias_conv1))\n",
    "print('\\n============================== Weight in FC ==============================\\n')\n",
    "print('Max w in W0: ', np.amax(W0), '\\nMin w in W0: ',  np.amin(W0))\n",
    "print('Max w in W1: ', np.amax(W1), '\\nMin w in W1: ',  np.amin(W1))\n",
    "print('Max w in W2: ', np.amax(W2), '\\nMin w in W2: ', np.amin(W2))\n",
    "print('\\n=================================== Bias in FC ===================================\\n')\n",
    "print('Max bias in B0: ', np.amax(B0), '\\nMin bias in B0: ',  np.amin(B0))\n",
    "print('Max bias in B1: ', np.amax(B1), '\\nMin bias in B1: ',  np.amin(B1))\n",
    "print('Max bias in B2: ', np.amax(B2), '\\nMin bias in B2: ', np.amin(B2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_image = 1\n",
    "min_image = -1\n",
    "\n",
    "max_filter_conv0 = 0.64\n",
    "min_filter_conv0 = -0.64\n",
    "max_filter_conv1 = 0.94\n",
    "min_filter_conv1 = -0.94\n",
    "\n",
    "max_result_conv0 = 2.67\n",
    "min_result_conv0 = -2.67\n",
    "max_result_conv1 = 8.88\n",
    "min_result_conv1 = -8.88\n",
    "\n",
    "max_bias_conv0 = 0.35\n",
    "min_bias_conv0 = -0.35\n",
    "max_bias_conv1 = 0.16\n",
    "min_bias_conv1 = -0.16\n",
    "\n",
    "max_pooling0 = 1.75\n",
    "min_pooling0 = -1.75\n",
    "max_pooling1 = 2.84\n",
    "min_pooling1 = -2.84\n",
    "\n",
    "max_w0 = 1.02\n",
    "min_w0 = -1.02\n",
    "max_w1 = 0.78\n",
    "min_w1 = -0.78\n",
    "max_w2 = 0.85\n",
    "min_w2 = -0.85\n",
    "\n",
    "max_b0 = 0.21\n",
    "min_b0 = -0.21\n",
    "max_b1 = 0.19\n",
    "min_b1 = -0.19\n",
    "max_b2 = 0.24\n",
    "min_b2 = -0.24\n",
    "\n",
    "max_in = 2.84\n",
    "min_in = -2.84\n",
    "max_hd0 = 9.6\n",
    "min_hd0 = -9.6\n",
    "max_hd1 = 12.8\n",
    "min_hd1 = -12.8\n",
    "max_out_bf_act = 23.4\n",
    "min_out_bf_act = 23.4\n",
    "max_out = 1\n",
    "min_out = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time to handle:  0.18200039863586426 s\n\n============================== Image ==============================\n\nMax value:  1.0 \nMin value:  0\n"
     ]
    }
   ],
   "source": [
    "pre_time = time.time()\n",
    "for i in range(10000):\n",
    "    if(max_image < np.amax(image_test[i])):\n",
    "        max_image = np.amax(image_test[i])\n",
    "    if(min_image > np.amin(image_test[i])):\n",
    "        min_image = np.amin(image_test[i])\n",
    "\n",
    "delta_time = (time.time() - pre_time)\n",
    "print('Time to handle: ', delta_time, 's')\n",
    "\n",
    "print('\\n============================== Image ==============================\\n')\n",
    "print('Max value: ', max_image, '\\nMin value: ', min_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing...  0 th test\n",
      "Processing...  1000 th test\n",
      "Processing...  2000 th test\n",
      "Processing...  3000 th test\n",
      "Processing...  4000 th test\n",
      "Processing...  5000 th test\n",
      "Processing...  6000 th test\n",
      "Processing...  7000 th test\n",
      "Processing...  8000 th test\n",
      "Processing...  9000 th test\n",
      "Time to handle:  7584.245477676392 s\n",
      "0.9893\n",
      "\n",
      "============================== Result in convolution layer ==============================\n",
      "\n",
      "Max result in conv layer 0:  2.564670004597997 \n",
      "Min result in conv layer 0:  -2.6674656270000003\n",
      "Max result in conv layer 1:  4.5858582353704085 \n",
      "Min result in conv layer 1:  -8.871344010236188\n",
      "Max result pooling in layer 0:  1.7406618107390415 \n",
      "Min result pooling in layer 0:  0\n",
      "Max result pooling in layer 1:  2.838221029965695 \n",
      "Min result pooling in layer 1:  0.0\n",
      "\n",
      "============================== Fully Connected ==============================\n",
      "\n",
      "Max value input:  2.838221029965695 \n",
      "Min value input:  0.0\n",
      "Max value in hd 0:  6.138875842161627 \n",
      "Min value in hd 0:  -9.599711009649864\n",
      "Max value in hd 1:  10.09026154265826 \n",
      "Min value in hd 1:  -12.771779724529198\n",
      "Max value output before softmax:  23.397701327967745 \n",
      "Min value output before softmax:  -20.651545853222462\n"
     ]
    }
   ],
   "source": [
    "num_test = 10000\n",
    "num_right = 0\n",
    "\n",
    "pre_time = time.time()\n",
    "\n",
    "for i in range(num_test):\n",
    "    if(i % 1000 == 0):\n",
    "        print('Processing... ', i, 'th test')\n",
    "    result, max_result_conv0, min_result_conv0, max_result_conv1, min_result_conv1, max_pooling0, min_pooling0, max_pooling1, min_pooling1, max_hd0, min_hd0, max_hd1, min_hd1, max_out_bf_act, min_out_gf_act = Feed_forward_Lenet_5(image_test[i], Conv0, Bias_conv0, Conv1, Bias_conv1, W0, W1, W2, B0, B1, B2, max_result_conv0, min_result_conv0, max_result_conv1, min_result_conv1, max_pooling0, min_pooling0, max_pooling1, min_pooling1, max_hd0, min_hd0, max_hd1, min_hd1, max_out_bf_act, min_out_gf_act)\n",
    "\n",
    "    if(result == label_test[i]):\n",
    "        num_right = num_right + 1\n",
    "\n",
    "delta_time = (time.time() - pre_time)\n",
    "print('Time to handle: ', delta_time, 's')\n",
    "\n",
    "accuracy = num_right / num_test\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "max_in = max_pooling1\n",
    "min_in = min_pooling1\n",
    "\n",
    "print('\\n============================== Result in convolution layer ==============================\\n')\n",
    "print('Max result in conv layer 0: ', max_result_conv0, '\\nMin result in conv layer 0: ', min_result_conv0)\n",
    "print('Max result in conv layer 1: ', max_result_conv1, '\\nMin result in conv layer 1: ', min_result_conv1)\n",
    "print('Max result pooling in layer 0: ', max_pooling0, '\\nMin result pooling in layer 0: ', min_pooling0)\n",
    "print('Max result pooling in layer 1: ', max_pooling1, '\\nMin result pooling in layer 1: ', min_pooling1)\n",
    "print('\\n============================== Fully Connected ==============================\\n')\n",
    "print('Max value input: ', max_in, '\\nMin value input: ', min_in)\n",
    "print('Max value in hd 0: ', max_hd0, '\\nMin value in hd 0: ', min_hd0)\n",
    "print('Max value in hd 1: ', max_hd1, '\\nMin value in hd 1: ', min_hd1)\n",
    "print('Max value output before sigmoid: ', max_out_bf_act, '\\nMin value output before sigmoid: ', min_out_gf_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================ Bit-width ============================================\n",
    "bit_width_image = 4\n",
    "bit_width_filter_conv0 = 4\n",
    "bit_width_filter_conv1 = 4\n",
    "bit_width_conv0 = 4\n",
    "bit_width_conv1 = 4\n",
    "bit_width_bias_conv0 = 4\n",
    "bit_width_bias_conv1 = 4\n",
    "bit_width_pooling0 = 4\n",
    "bit_width_pooling1 = 4\n",
    "bit_width_input = bit_width_pooling1\n",
    "\n",
    "bit_width_w0 = 4\n",
    "bit_width_w1 = 4\n",
    "bit_width_w2 = 4\n",
    "\n",
    "bit_width_b0 = 4\n",
    "bit_width_b1 = 4\n",
    "bit_width_b2 = 4\n",
    "\n",
    "bit_width_h0 = 4\n",
    "bit_width_h1 = 4\n",
    "bit_width_bf_sigmoid = 4\n",
    "bit_width_output = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================ Max-min quantization value ============================================\n",
    "max_image_q = 2**(bit_width_image-1)-1\n",
    "min_image_q = -2**(bit_width_image-1)\n",
    "max_filter_conv0_q = 2**(bit_width_filter_conv0-1)-1\n",
    "min_filter_conv0_q = -2**(bit_width_filter_conv0-1)\n",
    "max_filter_conv1_q = 2**(bit_width_filter_conv1-1)-1\n",
    "min_filter_conv1_q = -2**(bit_width_filter_conv1-1)\n",
    "max_conv0_q = 2**(bit_width_conv0-1)-1\n",
    "min_conv0_q = -2**(bit_width_conv0-1)\n",
    "max_conv1_q = 2**(bit_width_conv1-1)-1\n",
    "min_conv1_q = -2**(bit_width_conv1-1)\n",
    "max_bias_conv0_q = 2**(bit_width_bias_conv0-1)-1\n",
    "min_bias_conv0_q = -2**(bit_width_bias_conv0-1)\n",
    "max_bias_conv1_q = 2**(bit_width_bias_conv1-1)-1\n",
    "min_bias_conv1_q = -2**(bit_width_bias_conv1-1)\n",
    "max_pooling0_q = 2**(bit_width_pooling0-1)-1\n",
    "min_pooling0_q = -2**(bit_width_pooling0-1)\n",
    "max_pooling1_q = 2**(bit_width_pooling1-1)-1\n",
    "min_pooling1_q = -2**(bit_width_pooling1-1)\n",
    "\n",
    "max_w0_q = 2**(bit_width_w0-1)-1\n",
    "min_w0_q = -2**(bit_width_w0-1)\n",
    "max_w1_q = 2**(bit_width_w1-1)-1\n",
    "min_w1_q = -2**(bit_width_w1-1)\n",
    "max_w2_q = 2**(bit_width_w2-1)-1\n",
    "min_w2_q = -2**(bit_width_w2-1)\n",
    "\n",
    "max_b0_q = 2**(bit_width_b0-1)-1\n",
    "min_b0_q = -2**(bit_width_b0-1)\n",
    "max_b1_q = 2**(bit_width_b1-1)-1\n",
    "min_b1_q = -2**(bit_width_b1-1)\n",
    "max_b2_q = 2**(bit_width_b2-1)-1\n",
    "min_b2_q = -2**(bit_width_b2-1)\n",
    "\n",
    "max_input_q = 2**(bit_width_input-1)-1\n",
    "min_input_q = -2**(bit_width_input-1)\n",
    "max_hd0_q = 2**(bit_width_h0-1)-1\n",
    "min_hd0_q = -2**(bit_width_h0-1)\n",
    "max_hd1_q = 2**(bit_width_h1-1)-1\n",
    "min_hd1_q = -2**(bit_width_h1-1)\n",
    "max_bf_sigmoid_q = 2**(bit_width_bf_sigmoid-1)-1\n",
    "min_bf_sigmoid_q = -2**(bit_width_bf_sigmoid-1)\n",
    "max_output_q = 2**(bit_width_output-1)-1\n",
    "min_output_q = -2**(bit_width_output-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================ Scale and offset for w1 & bias ============================================\n",
    "# Quantied number = (X/Scale) + Offset\n",
    "scale_image = (max_image - min_image)/(max_image_q - min_image_q)\n",
    "scale_filter_conv0 = (max_filter_conv0 - min_filter_conv0)/(max_filter_conv0_q - min_filter_conv0_q)\n",
    "scale_filter_conv1 = (max_filter_conv1 - min_filter_conv1)/(max_filter_conv1_q - min_filter_conv1_q)\n",
    "scale_conv0 = (max_result_conv0 - min_result_conv0)/(max_conv0_q - min_conv0_q)\n",
    "scale_conv1 = (max_result_conv1 - min_result_conv1)/(max_conv1_q - min_conv1_q)\n",
    "scale_bias_conv0 = (max_bias_conv0 - min_bias_conv0)/(max_bias_conv0_q - min_bias_conv0_q)\n",
    "scale_bias_conv1 = (max_bias_conv1 - min_bias_conv1)/(max_bias_conv1_q - min_bias_conv1_q)\n",
    "scale_pooling0 = (max_pooling0 - min_pooling0)/(max_pooling0_q - min_pooling0_q)\n",
    "scale_pooling1 = (max_pooling1 - min_pooling1)/(max_pooling1_q - min_pooling1_q)\n",
    "\n",
    "scale_w0 = (max_w0 - min_w0)/(max_w0_q - min_w0_q)\n",
    "scale_w1 = (max_w1 - min_w1)/(max_w1_q - min_w1_q)\n",
    "scale_w2 = (max_w2 - min_w2)/(max_w2_q - min_w2_q)\n",
    "\n",
    "scale_b0 = (max_b0 - min_b0)/(max_b0_q - min_b0_q)\n",
    "scale_b1 = (max_b1 - min_b1)/(max_b1_q - min_b1_q)\n",
    "scale_b2 = (max_b2 - min_b2)/(max_b2_q - min_b2_q)\n",
    "\n",
    "scale_input = (max_in - min_in)/(max_input_q - min_input_q)\n",
    "scale_hd0 = (max_hd0 - min_hd0)/(max_hd0_q - min_hd0_q)\n",
    "scale_hd1 = (max_hd1 - min_hd1)/(max_hd1_q - min_hd1_q)\n",
    "scale_bf_sigmoid = (max_out_bf_act - min_out_bf_act)/(max_bf_sigmoid_q - min_bf_sigmoid_q)\n",
    "scale_output = (max_out - min_out)/(max_output_q - min_output_q)\n",
    "\n",
    "offset_image = round((max_image*min_image_q - min_image*max_image_q)/(max_image - min_image))\n",
    "offset_filter_conv0 = round((max_filter_conv0*min_filter_conv0_q - min_filter_conv0*max_filter_conv0_q)/(max_filter_conv0 - min_filter_conv0))\n",
    "offset_filter_conv1 = round((max_filter_conv1*min_filter_conv1_q - min_filter_conv1*max_filter_conv1_q)/(max_filter_conv1 - min_filter_conv1))\n",
    "offset_conv0 = round((max_result_conv0*min_conv0_q - min_result_conv0*max_conv0_q)/(max_result_conv0 - min_result_conv0))\n",
    "offset_conv1 = round((max_result_conv1*min_conv1_q - min_result_conv1*max_conv1_q)/(max_result_conv1 - min_result_conv1))\n",
    "offset_bias_conv0 = round((max_bias_conv0*min_bias_conv0_q - min_bias_conv0*max_bias_conv0_q)/(max_bias_conv0 - min_bias_conv0))\n",
    "offset_bias_conv1 = round((max_bias_conv1*min_bias_conv1_q - min_bias_conv1*max_bias_conv1_q)/(max_bias_conv1 - min_bias_conv1))\n",
    "offset_pooling0 = round((max_pooling0*min_pooling0_q - min_pooling0*max_pooling0_q)/(max_pooling0 - min_pooling0))\n",
    "offset_pooling1 = round((max_pooling1*min_pooling1_q - min_pooling1*max_pooling1_q)/(max_pooling1 - min_pooling1))\n",
    "\n",
    "offset_w0 = round((max_w0*min_w0_q - min_w0*max_w0_q)/(max_w0 - min_w0))\n",
    "offset_w1 = round((max_w1*min_w1_q - min_w1*max_w1_q)/(max_w1 - min_w1))\n",
    "offset_w2 = round((max_w2*min_w2_q - min_w2*max_w2_q)/(max_w2 - min_w2))\n",
    "\n",
    "offset_b0 = round((max_b0*min_b0_q - min_b0*max_b0_q)/(max_b0 - min_b0))\n",
    "offset_b1 = round((max_b1*min_b1_q - min_b1*max_b1_q)/(max_b1 - min_b1))\n",
    "offset_b2 = round((max_b2*min_b2_q - min_b2*max_b2_q)/(max_b2 - min_b2))\n",
    "\n",
    "offset_input = round((max_in*min_input_q - min_in*max_input_q)/(max_in - min_in))\n",
    "offset_hd0 = round((max_hd0*min_hd0_q - min_hd0*max_hd0_q)/(max_hd0 - min_hd0))\n",
    "offset_hd1 = round((max_hd1*min_hd1_q - min_hd1*max_hd1_q)/(max_hd1 - min_hd1))\n",
    "offset_bf_sigmoid = round((max_out_bf_act*min_bf_sigmoid_q - min_out_bf_act*max_bf_sigmoid_q)/(max_out_bf_act - min_out_bf_act))\n",
    "offset_output = round((max_out*min_output_q - min_out*max_output_q)/(max_out - min_out))\n",
    "\n",
    "# ============================================ Scale for quantize ============================================\n",
    "# X * Scale \n",
    "scale_calculate_convolution_0 = (scale_image*scale_filter_conv0)/scale_conv0\n",
    "scale_for_pooling = scale_conv0/(scale_pooling0*4)\n",
    "scale_calculate_convolution_1 = (scale_pooling0*scale_filter_conv1)/scale_conv1\n",
    "scale_for_pooling = scale_conv1/(scale_pooling1*4)\n",
    "\n",
    "scale_for_W0_x_Flatten = (scale_input*scale_w0)/scale_hd0\n",
    "scale_for_W1_x_hd0 = (scale_hd0*scale_w1)/scale_hd1\n",
    "scale_for_W2_x_hd1 = (scale_hd1*scale_w2)/scale_bf_sigmoid"
   ]
  }
 ]
}